Objetivo: desarrollar un prototipo funcional utilizando una arquitectura de Transformer para la detecci贸n de turbidez en aguas residuales
Datos: los datos otorgados por el dataset de prueba (sample).
Preparaci贸n: ambos se sincronizan temporalmente para asegurar que cada firma espectral correspondiera a su medici贸n de turbidez correcta.
             Se divide en un 80% para entrenamiento y un 20% para prueba. La matriz de caracter铆sticas X fue normalizada utilizando StandardScaler de Scikit-learn para estandarizar el rango de los datos de entrada, un paso crucial para el correcto entrenamiento de redes neuronales.

Modelo
modelo de regresi贸n basado en la arquitectura Transformer Encoder utilizando PyTorch.

El modelo fue entrenado durante 200 茅pocas con el objetivo de minimizar el Error Cuadr谩tico Medio (MSE) entre sus predicciones y los valores reales de turbidez, utilizando el optimizador Adam.

En resumen, elegimos el Encoder-Only porque nuestro objetivo no es generar un nuevo espectro ni traducirlo, sino entenderlo a fondo para poder clasificarlo.

---Resultados para la Turbidez en el Paper UDP

Long Short-Term Memory (LSTM).

AUC (rea bajo la curva): 0,688 
F1-score: 0,549 
Exactitud (Accuracy): 73,2% 
Brecha de Generalizaci贸n (Gap): 13,0%

Como el modelo v1 es de regresi贸n, se transforma a clasificaci贸n y se 
ocupan los mismos umbrales que el paper de la udp para crear las clases y 
calcular las m茅tricas.

Evaluaci贸n de Regresi贸n: Inicialmente, el modelo se evalu贸 en su tarea principal de regresi贸n sobre el conjunto de prueba, obteniendo un MSE final.

Conversi贸n a Clasificaci贸n: Para comparar con las m茅tricas del paper (F1-score y AUC), se transform贸 el problema de regresi贸n a uno de clasificaci贸n binaria ("Bajo" vs. "Alto"), adoptando exactamente los mismos umbrales definidos en la tesis:

Clase "Bajo" (0): Mediciones con turbidez < 50 NTU.

Clase "Alto" (1): Mediciones con turbidez > 150 NTU.

Para asegurar una comparaci贸n equitativa, todas las muestras del conjunto de prueba con valores de turbidez entre 50 y 150 NTU fueron excluidas del c谩lculo de las m茅tricas de clasificaci贸n, replicando la metodolog铆a del paper que busca una separaci贸n clara entre clases. Con las predicciones y etiquetas ya binarizadas, se procedi贸 a calcular el F1-Score y el AUC.

-- Comparaci贸n y resultados 

Usando los umbrales del paper para clasificaci贸n: Bajo (<50.0) y Alto (>150.0).     
De las 945 muestras de prueba, se usar谩n 223 para la comparaci贸n (excluyendo valores intermedios).
F1-Score (m茅todo paper): 0.9389
AUC (m茅todo paper): 1.0000

--- Comparaci贸n Final con el Paper (para Turbidez) ---
M茅trica      | Tu Transformer | Paper (LSTM)
-------------|----------------|---------------
F1-Score     | 0.9389         | 0.5490
AUC          | 1.0000         | 0.6880
-------------------------------------------------

AUC (1.0000 vs. 0.6880)
Este es el resultado m谩s impresionante. Un AUC de 1.0 es la puntuaci贸n perfecta .

Significa que tu modelo puede distinguir perfectamente entre las muestras de turbidez "Baja" y "Alta" en el conjunto de prueba. Si le das una muestra de cada clase, siempre asignar谩 una "probabilidad" m谩s alta a la muestra de la clase "Alta". No hay ambig眉edad en su capacidad de separaci贸n. El modelo del paper (0.6880) ten铆a una capacidad de distinci贸n considerablemente m谩s d茅bil.